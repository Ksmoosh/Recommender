{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import recommender_utils\n",
    "import math\n",
    "import copy\n",
    "\n",
    "import model_CNN as model_cnn\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset treningowy:\n",
      "\tEmbeddings: 427 uzytkowników, 8500 filmów\n",
      "\tX wymiar: (68495, 2)\n",
      "\tY shape: (68495,)\n",
      "426\n",
      "8499\n",
      "Dataset walidacyjny:\n",
      "\tEmbeddings: 61 uzytkowników, 5536 filmów\n",
      "\tX wymiar: (17280, 2)\n",
      "\tY shape: (17280,)\n",
      "60\n",
      "5535\n",
      "Dataset testowy:\n",
      "\tEmbeddings: 122 uzytkowników, 3975 filmów\n",
      "\tX wymiar: (15061, 2)\n",
      "\tY shape: (15061,)\n",
      "121\n",
      "3974\n"
     ]
    }
   ],
   "source": [
    "movie_df, movie_feature_headers, num_feature_headers = recommender_utils.get_movies_data(filepath='data_small/movies.csv', separator=r',', movies_columns_to_drop=['genres'], only_genres=False)\n",
    "\n",
    "data_train = recommender_utils.get_ratings_data(filepath='data_small/train.csv', separator=r',', dtypes=recommender_utils.dtypes)\n",
    "data_val = recommender_utils.get_ratings_data(filepath='data_small/validate.csv', separator=r',', dtypes=recommender_utils.dtypes)\n",
    "data_test = recommender_utils.get_ratings_data(filepath='data_small/test.csv', separator=r',', dtypes=recommender_utils.dtypes)\n",
    "\n",
    "(num_users_train, num_movies_train), (X_train, y_train), _ = recommender_utils.create_dataset_cnn(data_train)\n",
    "(num_users_val, num_movies_val), (X_val, y_val), _ = recommender_utils.create_dataset_cnn(data_val)\n",
    "(num_users_test, num_movies_test), (X_test, y_test), _ = recommender_utils.create_dataset_cnn(data_test)\n",
    "\n",
    "\n",
    "print(\"Dataset treningowy:\")\n",
    "print(f\"\\tEmbeddings: {num_users_train} uzytkowników, {num_movies_train} filmów\")\n",
    "print(f\"\\tX wymiar: {X_train.shape}\")\n",
    "print(f\"\\tY shape: {y_train.shape}\")\n",
    "print(X_train.user_id.max())\n",
    "print(X_train.movie_id.max())\n",
    "\n",
    "print(\"Dataset walidacyjny:\")\n",
    "print(f\"\\tEmbeddings: {num_users_val} uzytkowników, {num_movies_val} filmów\")\n",
    "print(f\"\\tX wymiar: {X_val.shape}\")\n",
    "print(f\"\\tY shape: {y_val.shape}\")\n",
    "print(X_val.user_id.max())\n",
    "print(X_val.movie_id.max())\n",
    "\n",
    "print(\"Dataset testowy:\")\n",
    "print(f\"\\tEmbeddings: {num_users_test} uzytkowników, {num_movies_test} filmów\")\n",
    "print(f\"\\tX wymiar: {X_test.shape}\")\n",
    "print(f\"\\tY shape: {y_test.shape}\")\n",
    "print(X_test.user_id.max())\n",
    "print(X_test.movie_id.max())\n",
    "\n",
    "datasets = {'train': (X_train, y_train), 'val': (X_val, y_val)}\n",
    "dataset_sizes = {'train': len(X_train), 'val': len(X_val)}\n",
    "\n",
    "minmax = y_train.min().astype(float), y_train.max().astype(float)\n",
    "\n",
    "num_users_all = num_users_train + num_users_val + num_users_test\n",
    "num_movies_all = num_movies_train + num_movies_val + num_movies_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model_cnn.EmbeddingNet(\n",
    " #   n_users=num_users_all, n_movies=num_movies_all, \n",
    "  #  n_factors=150, hidden=[500, 500, 500], \n",
    "   # embedding_dropout=0.05, dropouts=[0.5, 0.5, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_cnn.ConvEmbeddingNet(\n",
    "    n_users=num_users_all, n_movies=num_movies_all, \n",
    "    n_factors=150, hidden=[500, 500, 500], \n",
    "    embedding_dropout=0.05, dropouts=[0.5, 0.5, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/100] train: 1.6522 - val: 1.4264\n",
      "loss improvement on epoch: 2\n",
      "[002/100] train: 1.6347 - val: 1.4094\n",
      "loss improvement on epoch: 3\n",
      "[003/100] train: 1.6152 - val: 1.3909\n",
      "loss improvement on epoch: 4\n",
      "[004/100] train: 1.5943 - val: 1.3702\n",
      "loss improvement on epoch: 5\n",
      "[005/100] train: 1.5702 - val: 1.3473\n",
      "loss improvement on epoch: 6\n",
      "[006/100] train: 1.5440 - val: 1.3209\n",
      "loss improvement on epoch: 7\n",
      "[007/100] train: 1.5133 - val: 1.2922\n",
      "loss improvement on epoch: 8\n",
      "[008/100] train: 1.4805 - val: 1.2610\n",
      "loss improvement on epoch: 9\n",
      "[009/100] train: 1.4444 - val: 1.2280\n",
      "loss improvement on epoch: 10\n",
      "[010/100] train: 1.4062 - val: 1.1942\n",
      "loss improvement on epoch: 11\n",
      "[011/100] train: 1.3691 - val: 1.1605\n",
      "loss improvement on epoch: 12\n",
      "[012/100] train: 1.3304 - val: 1.1289\n",
      "loss improvement on epoch: 13\n",
      "[013/100] train: 1.2960 - val: 1.0992\n",
      "loss improvement on epoch: 14\n",
      "[014/100] train: 1.2621 - val: 1.0738\n",
      "loss improvement on epoch: 15\n",
      "[015/100] train: 1.2330 - val: 1.0503\n",
      "loss improvement on epoch: 16\n",
      "[016/100] train: 1.2069 - val: 1.0334\n",
      "loss improvement on epoch: 17\n",
      "[017/100] train: 1.1857 - val: 1.0160\n",
      "loss improvement on epoch: 18\n",
      "[018/100] train: 1.1693 - val: 1.0074\n",
      "loss improvement on epoch: 19\n",
      "[019/100] train: 1.1563 - val: 0.9997\n",
      "loss improvement on epoch: 20\n",
      "[020/100] train: 1.1470 - val: 0.9963\n",
      "loss improvement on epoch: 21\n",
      "[021/100] train: 1.1410 - val: 0.9923\n",
      "[022/100] train: 1.1358 - val: 0.9933\n",
      "[023/100] train: 1.1349 - val: 0.9929\n",
      "loss improvement on epoch: 24\n",
      "[024/100] train: 1.1305 - val: 0.9922\n",
      "loss improvement on epoch: 25\n",
      "[025/100] train: 1.1303 - val: 0.9913\n",
      "[026/100] train: 1.1305 - val: 0.9940\n",
      "[027/100] train: 1.1300 - val: 0.9925\n",
      "[028/100] train: 1.1302 - val: 0.9951\n",
      "[029/100] train: 1.1318 - val: 0.9929\n",
      "[030/100] train: 1.1296 - val: 0.9928\n",
      "[031/100] train: 1.1311 - val: 0.9941\n",
      "[032/100] train: 1.1306 - val: 0.9947\n",
      "[033/100] train: 1.1286 - val: 0.9945\n",
      "[034/100] train: 1.1304 - val: 0.9944\n",
      "[035/100] train: 1.1304 - val: 0.9943\n",
      "early stopping after epoch 035\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 1\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.cuda.manual_seed(RANDOM_STATE)\n",
    "lr = 1e-6\n",
    "wd = 1e-5\n",
    "# for linear 1000 works, for conv 1000 does not\n",
    "# bs = 1000\n",
    "bs = 300\n",
    "n_epochs = 100\n",
    "patience = 10\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "use_scheduler = False\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
    "if use_scheduler:\n",
    "    scheduler = model_cnn.CyclicLR(optimizer, model_cnn.cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "    \n",
    "    for phase in ('train', 'val'):\n",
    "        training = phase == 'train'\n",
    "        running_loss = 0.0\n",
    "        n_batches = 0\n",
    "        \n",
    "        for batch in model_cnn.batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = model(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                \n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    if use_scheduler:\n",
    "                        scheduler.step()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    if use_scheduler:\n",
    "                        lr_history.extend(scheduler.get_lr())\n",
    "                    \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        \n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "                best_weights = copy.deepcopy(model.state_dict())\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "                \n",
    "    history.append(stats)\n",
    "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_weights, \"models/cnn_100epochs_wo_features_base.pt\")\n",
    "#epochs_80_with_20_features = loss_through_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'epoch': 1, 'total': 100, 'train': 1.6522281200348508, 'val': 1.4264369673199124}, {'epoch': 2, 'total': 100, 'train': 1.6346701385522553, 'val': 1.4094229998411956}, {'epoch': 3, 'total': 100, 'train': 1.615244218417089, 'val': 1.3908839631963659}, {'epoch': 4, 'total': 100, 'train': 1.5942582345198555, 'val': 1.3702423713825367}, {'epoch': 5, 'total': 100, 'train': 1.5701569643862292, 'val': 1.3472909609476724}, {'epoch': 6, 'total': 100, 'train': 1.543974967949303, 'val': 1.320873851246304}, {'epoch': 7, 'total': 100, 'train': 1.5132552462343283, 'val': 1.2922321725774695}, {'epoch': 8, 'total': 100, 'train': 1.48048256010076, 'val': 1.2610000389593619}, {'epoch': 9, 'total': 100, 'train': 1.444400892557737, 'val': 1.228015998557762}, {'epoch': 10, 'total': 100, 'train': 1.40622381667985, 'val': 1.1942142371778135}, {'epoch': 11, 'total': 100, 'train': 1.3691254346020352, 'val': 1.1604599802582352}, {'epoch': 12, 'total': 100, 'train': 1.3303933357825217, 'val': 1.128865404482241}, {'epoch': 13, 'total': 100, 'train': 1.295972307014312, 'val': 1.099177402920193}, {'epoch': 14, 'total': 100, 'train': 1.262067378856064, 'val': 1.073835055033366}, {'epoch': 15, 'total': 100, 'train': 1.2330386584445032, 'val': 1.050338833420365}, {'epoch': 16, 'total': 100, 'train': 1.2069082231032204, 'val': 1.033367094287166}, {'epoch': 17, 'total': 100, 'train': 1.1856858345720662, 'val': 1.0160341148023253}, {'epoch': 18, 'total': 100, 'train': 1.1692810771465127, 'val': 1.0074279374546475}, {'epoch': 19, 'total': 100, 'train': 1.1562853806975533, 'val': 0.9997252137572677}, {'epoch': 20, 'total': 100, 'train': 1.14695490664379, 'val': 0.9963066705950985}, {'epoch': 21, 'total': 100, 'train': 1.1409906998978312, 'val': 0.9922950214809841}, {'epoch': 22, 'total': 100, 'train': 1.1358143367665694, 'val': 0.9933453427420722}, {'epoch': 23, 'total': 100, 'train': 1.134917395316264, 'val': 0.9929364094027766}, {'epoch': 24, 'total': 100, 'train': 1.1305234040663323, 'val': 0.9922095585752416}, {'epoch': 25, 'total': 100, 'train': 1.1303086885440714, 'val': 0.991305304898156}, {'epoch': 26, 'total': 100, 'train': 1.1304734825748572, 'val': 0.9939768208397759}, {'epoch': 27, 'total': 100, 'train': 1.1300255275675917, 'val': 0.9924713019971494}, {'epoch': 28, 'total': 100, 'train': 1.130182506745902, 'val': 0.9950697669276485}, {'epoch': 29, 'total': 100, 'train': 1.1317629777877833, 'val': 0.9929046970826608}, {'epoch': 30, 'total': 100, 'train': 1.1296034212764732, 'val': 0.9927924721329301}, {'epoch': 31, 'total': 100, 'train': 1.1310636736892576, 'val': 0.9941163045388681}, {'epoch': 32, 'total': 100, 'train': 1.1306109714041628, 'val': 0.994728970086133}, {'epoch': 33, 'total': 100, 'train': 1.1285761958987655, 'val': 0.9944509916835361}, {'epoch': 34, 'total': 100, 'train': 1.1304361238820038, 'val': 0.9943775199077748}, {'epoch': 35, 'total': 100, 'train': 1.1304172748944665, 'val': 0.994283409471865}]\n",
      "{'epoch': 35, 'total': 100, 'train': 1.1304172748944665, 'val': 0.994283409471865}\n"
     ]
    }
   ],
   "source": [
    "print(history)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0958542281448995\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "n_batches = 0\n",
    "\n",
    "for batch in model_cnn.batches(X_test, y_test, shuffle=False, bs=bs):\n",
    "    x_batch, y_batch = [b.to(device) for b in batch]\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "    running_loss += loss.item()\n",
    "    \n",
    "test_loss = running_loss / len(X_test)\n",
    "print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [500, 300, 1], expected input[1, 2, 300] to have 300 channels, but got 2 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m x_batch, y_batch \u001b[39m=\u001b[39m [b\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m batch]\n\u001b[1;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m----> 6\u001b[0m     outputs \u001b[39m=\u001b[39m model(x_batch[:, \u001b[39m0\u001b[39;49m], x_batch[:, \u001b[39m1\u001b[39;49m], minmax)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(x_batch)\n\u001b[1;32m      8\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Nauka/Studia/Magisterskie/Magisterka/Recommender/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Nauka/Studia/Magisterskie/Magisterka/Recommender/model_CNN.py:52\u001b[0m, in \u001b[0;36mConvEmbeddingNet.forward\u001b[0;34m(self, users, movies, minmax)\u001b[0m\n\u001b[1;32m     50\u001b[0m features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mu(users), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm(movies)], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     51\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop(features)\n\u001b[0;32m---> 52\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtranspose(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden(x), \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     53\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(x))\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m minmax \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Nauka/Studia/Magisterskie/Magisterka/Recommender/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Nauka/Studia/Magisterskie/Magisterka/Recommender/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Nauka/Studia/Magisterskie/Magisterka/Recommender/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Nauka/Studia/Magisterskie/Magisterka/Recommender/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Documents/Nauka/Studia/Magisterskie/Magisterka/Recommender/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [500, 300, 1], expected input[1, 2, 300] to have 300 channels, but got 2 channels instead"
     ]
    }
   ],
   "source": [
    "bs=2\n",
    "for batch in model_cnn.batches(X_test, y_test, shuffle=False, bs=bs):\n",
    "    x_batch, y_batch = [b.to(device) for b in batch]\n",
    "    \n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "    print(x_batch)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f24bbe3eee7f1671aa96cb4424e1ae784be864432abf663e2856784d4fd29d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
